{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d7ec41b",
   "metadata": {},
   "source": [
    "## Testing on Apple Open ELM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55baad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd11caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "{\"role\": \"system\", \"content\": \"You are a customer agent\"},\n",
    "{\"role\": \"user\", \"content\": \"What is the sentiment of this sentence:I am feeling happy\"},\n",
    "{\"role\": \"assistant\", \"content\": \"positive\"},\n",
    "{\"role\": \"user\", \"content\": \"What is the sentiment of this sentence: The music festival was an auditory feast of eclectic tunes and talented artists, yet the overcrowding and logistical mishaps dampened the overall experience\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33fbbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Nice to meet you!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can I ask a question?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7460f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wengz\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\wengz\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\wengz\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"apple/OpenELM-270M-Instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44514b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"C:/Users/wengz/Desktop/apple/OpenELM-270M-Instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e78604",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"C:/Users/wengz/Desktop/apple/OpenELM-270M-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8838cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wengz\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"apple/OpenELM-450M-Instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7cb5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"apple/OpenELM-1_1B-Instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f789a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"C:/Users/wengz/Desktop/apple/OpenELM-1_1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "698856f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"C:/Users/wengz/Desktop/apple/OpenELM-450M-Instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b803c92",
   "metadata": {},
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "   \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    token=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b48de41",
   "metadata": {},
   "source": [
    "tokenizer.save_pretrained(\"llama2hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb3f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"llama2hf\", pad_token_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "420c4e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32001, 1280)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32d32d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] <<SYS>>\\nYou are a customer agent\\n<</SYS>>\\n\\nWhat is the sentiment of this sentence:I am feeling happy [/INST] positive </s><s>[INST] What is the sentiment of this sentence: The music festival was an auditory feast of eclectic tunes and talented artists, yet the overcrowding and logistical mishaps dampened the overall experience [/INST]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b5428a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "The Government provides the following premium subsidies and support to keep premiums affordable:\n",
    "\n",
    "Premium Subsidies (up to 50%) for lower- to middle-income Singapore Residents with household monthly income per person of $2,800 and below and living in residences with an Annual Value of $25,000 and below. Individuals who own multiple properties will not be eligible. Permanent Residents (PRs) will receive half the applicable Singapore Citizens (SCs) rate.\n",
    "\n",
    "Additional Merdeka Generation (MG) Subsidies of up to 10% for all MGs, on top of above premium subsidies. MGs will also receive annual MediSave top-ups of $200 from 2019 to 2023, which can be used to pay premiums.\n",
    "\n",
    "Special Pioneer Generation (PG) Subsidies of up to 60% for all PG seniors. PGs will also receive lifetime annual Medisave top-ups of $250 - $900 a year, which can be used to pay premiums. Older PGs (aged 82 years old and above in 2021) who have serious pre-existing conditions will also receive an additional one-off annual MediSave top-up of $50-$200 for five years, from 2021 to 2025. PGs aged 87 years old and above in 2021 will have premiums fully covered by the government, while younger PGs will have about two-thirds of premiums covered.\n",
    "\n",
    "Additional Premium Support for needy Singaporeans who cannot afford their premiums even after the above subsidies and MediSave use, and have limited family support.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3115a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "What are the subsidies I am eligible for as a Singaporean?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3e0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\":500,\n",
    "    \"do_sample\":True,\n",
    "    \"num_beams\": 5,\n",
    "    \"do_sample\":True,\n",
    "    \"early_stopping\":True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05ffa7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\n",
    "\"text-generation\",\n",
    "model=model,\n",
    "tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1261c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = [\n",
    "{\"role\": \"system\", \"content\": \"You are a experienced operation assistant\"},\n",
    "{\"role\": \"user\", \"content\": f\"Based on the context provided, context: ```{context}```, could you answer the following query: ```{query}```\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c89c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_tmpl_str = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    f\"{context}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query.\\n\"\n",
    "    f\"Query: {query}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa22bba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = pipe(qa_prompt_tmpl_str, **generation_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3419c583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Context information is below.\\n---------------------\\n\\nThe Government provides the following premium subsidies and support to keep premiums affordable:\\n\\nPremium Subsidies (up to 50%) for lower- to middle-income Singapore Residents with household monthly income per person of $2,800 and below and living in residences with an Annual Value of $25,000 and below. Individuals who own multiple properties will not be eligible. Permanent Residents (PRs) will receive half the applicable Singapore Citizens (SCs) rate.\\n\\nAdditional Merdeka Generation (MG) Subsidies of up to 10% for all MGs, on top of above premium subsidies. MGs will also receive annual MediSave top-ups of $200 from 2019 to 2023, which can be used to pay premiums.\\n\\nSpecial Pioneer Generation (PG) Subsidies of up to 60% for all PG seniors. PGs will also receive lifetime annual Medisave top-ups of $250 - $900 a year, which can be used to pay premiums. Older PGs (aged 82 years old and above in 2021) who have serious pre-existing conditions will also receive an additional one-off annual MediSave top-up of $50-$200 for five years, from 2021 to 2025. PGs aged 87 years old and above in 2021 will have premiums fully covered by the government, while younger PGs will have about two-thirds of premiums covered.\\n\\nAdditional Premium Support for needy Singaporeans who cannot afford their premiums even after the above subsidies and MediSave use, and have limited family support.\\n\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: \\nWhat are the subsidies I am eligible for as a Singaporean?\\n\\nAnswer: \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "719662de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Context information is below.\\n---------------------\\n\\nThe Government provides the following premium subsidies and support to keep premiums affordable:\\n\\nPremium Subsidies (up to 50%) for lower- to middle-income Singapore Residents with household monthly income per person of $2,800 and below and living in residences with an Annual Value of $25,000 and below. Individuals who own multiple properties will not be eligible. Permanent Residents (PRs) will receive half the applicable Singapore Citizens (SCs) rate.\\n\\nAdditional Merdeka Generation (MG) Subsidies of up to 10% for all MGs, on top of above premium subsidies. MGs will also receive annual MediSave top-ups of $200 from 2019 to 2023, which can be used to pay premiums.\\n\\nSpecial Pioneer Generation (PG) Subsidies of up to 60% for all PG seniors. PGs will also receive lifetime annual Medisave top-ups of $250 - $900 a year, which can be used to pay premiums. Older PGs (aged 82 years old and above in 2021) who have serious pre-existing conditions will also receive an additional one-off annual MediSave top-up of $50-$200 for five years, from 2021 to 2025. PGs aged 87 years old and above in 2021 will have premiums fully covered by the government, while younger PGs will have about two-thirds of premiums covered.\\n\\nAdditional Premium Support for needy Singaporeans who cannot afford their premiums even after the above subsidies and MediSave use, and have limited family support.\\n\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: \\nWhat are the subsidies I am eligible for as a Singaporean?\\n\\nAnswer: \\nLower- to middle-income Singapore Residents with household monthly income per person of $2,800 and below and living in residences with an Annual Value of $25,000 and below.\\n\\n1. Permanent Residents (PRs) will receive half the applicable Singapore Citizens (SC) rate.\\n\\n2. Additional Merdeka Generation (MG) of up to 10% for all MGs, on top of above premium subsidies. MGs will also receive annual MediSave top-ups of $200 from 2019 to 2023, which can be used to pay premiums.\\n\\n3. Special Pioneer Generation (PG) of up to 60% for all PG seniors. PGs will also receive lifetime annual Medisave top-ups of $250 - $900 a year, which can be used to pay premiums.\\n\\n4. Older PGs (aged 82 years old and above in 2021) who have serious pre-existing conditions will also receive an additional one-off annual MediSave top-up of $50-$200 for five years, from 2021 to 2025. PGs aged 87 years old and above in 2021 will have premiums fully covered by the government, while younger PGs will have about two-thirds of premiums covered.\\n\\n5. Additional Premium Support for needy Singaporeans who cannot afford their premiums even after the above subsidies and MediSave use, and have limited family support.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "translation_generation_config = GenerationConfig(\n",
    "    num_beams=4,\n",
    "    early_stopping=True,\n",
    "    decoder_start_token_id=0,\n",
    "    max_new_tokens=2048\n",
    ")\n",
    "\n",
    "inputs = tokenizer(qa_prompt_tmpl_str, return_tensors=\"pt\", )\n",
    "outputs = model.generate(**inputs, generation_config=translation_generation_config)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f968633",
   "metadata": {},
   "source": [
    "## Testing Microsoft Phi 3\n",
    "\n",
    "- https://github.com/microsoft/onnxruntime-genai/blob/main/examples/python/phi-3-tutorial.md\n",
    "- Can only run individually on the script for now and will need to check when the integration will be in HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8109c39f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Cannot determine framework from given checkpoint location. There should be a pytorch_model*.bin for PyTorch or tf_model*.h5 for TensorFlow.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptimum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORTModelForCausalLM\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mORTModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/Phi-3-mini-4k-instruct-onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\onnxruntime\\modeling_ort.py:669\u001b[0m, in \u001b[0;36mORTModel.from_pretrained\u001b[1;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, provider, session_options, provider_options, use_io_binding, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;129m@add_start_docstrings\u001b[39m(FROM_PRETRAINED_START_DOCSTRING)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    637\u001b[0m ):\n\u001b[0;32m    638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m    provider (`str`, defaults to `\"CPUExecutionProvider\"`):\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m        ONNX Runtime provider to use for loading the model. See https://onnxruntime.ai/docs/execution-providers/ for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;124;03m        `ORTModel`: The loaded ORTModel model.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_io_binding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_io_binding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\modeling_base.py:402\u001b[0m, in \u001b[0;36mOptimizedModel.from_pretrained\u001b[1;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    400\u001b[0m from_pretrained_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_transformers \u001b[38;5;28;01mif\u001b[39;00m export \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained\n\u001b[1;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_pretrained_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\onnxruntime\\modeling_decoder.py:608\u001b[0m, in \u001b[0;36mORTModelForCausalLM._from_transformers\u001b[1;34m(cls, model_id, config, use_auth_token, revision, force_download, cache_dir, subfolder, local_files_only, trust_remote_code, use_cache, use_merged, provider, session_options, provider_options, use_io_binding, task)\u001b[0m\n\u001b[0;32m    605\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m TemporaryDirectory()\n\u001b[0;32m    606\u001b[0m save_dir_path \u001b[38;5;241m=\u001b[39m Path(save_dir\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 608\u001b[0m \u001b[43mmain_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_post_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m config\u001b[38;5;241m.\u001b[39msave_pretrained(save_dir_path)\n\u001b[0;32m    625\u001b[0m maybe_save_preprocessors(model_id, save_dir_path, src_subfolder\u001b[38;5;241m=\u001b[39msubfolder)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\exporters\\onnx\\__main__.py:214\u001b[0m, in \u001b[0;36mmain_export\u001b[1;34m(model_name_or_path, output, task, opset, device, dtype, fp16, optimize, monolith, no_post_process, framework, atol, cache_dir, trust_remote_code, pad_token_id, subfolder, revision, force_download, local_files_only, use_auth_token, for_ort, do_validation, model_kwargs, custom_onnx_configs, fn_get_submodels, use_subprocess, _variant, library_name, legacy, no_dynamic_axes, do_constant_folding, **kwargs_shapes)\u001b[0m\n\u001b[0;32m    211\u001b[0m original_task \u001b[38;5;241m=\u001b[39m task\n\u001b[0;32m    212\u001b[0m task \u001b[38;5;241m=\u001b[39m TasksManager\u001b[38;5;241m.\u001b[39mmap_from_synonym(task)\n\u001b[1;32m--> 214\u001b[0m framework \u001b[38;5;241m=\u001b[39m \u001b[43mTasksManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetermine_framework\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m library_name \u001b[38;5;241m=\u001b[39m TasksManager\u001b[38;5;241m.\u001b[39minfer_library_from_model(\n\u001b[0;32m    216\u001b[0m     model_name_or_path, subfolder\u001b[38;5;241m=\u001b[39msubfolder, library_name\u001b[38;5;241m=\u001b[39mlibrary_name\n\u001b[0;32m    217\u001b[0m )\n\u001b[0;32m    219\u001b[0m torch_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\exporters\\tasks.py:1493\u001b[0m, in \u001b[0;36mTasksManager.determine_framework\u001b[1;34m(model_name_or_path, subfolder, framework, cache_dir)\u001b[0m\n\u001b[0;32m   1489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RequestsConnectionError(\n\u001b[0;32m   1490\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe framework could not be automatically inferred. If using the command-line, please provide the argument --framework (pt,tf) Detailed error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_exception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1491\u001b[0m         )\n\u001b[0;32m   1492\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1493\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1494\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot determine framework from given checkpoint location.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1495\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m There should be a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(WEIGHTS_NAME)\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(WEIGHTS_NAME)\u001b[38;5;241m.\u001b[39msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for PyTorch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1496\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(TF2_WEIGHTS_NAME)\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(TF2_WEIGHTS_NAME)\u001b[38;5;241m.\u001b[39msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for TensorFlow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m   1500\u001b[0m     framework \u001b[38;5;241m=\u001b[39m framework \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Cannot determine framework from given checkpoint location. There should be a pytorch_model*.bin for PyTorch or tf_model*.h5 for TensorFlow."
     ]
    }
   ],
   "source": [
    "from optimum.onnxruntime import ORTModelForCausalLM\n",
    "model = ORTModelForCausalLM.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct-onnx\", trust_remote_code=True, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9eaa17",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Loading microsoft/Phi-3-mini-4k-instruct-onnx requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptimum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m----> 2\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/Phi-3-mini-4k-instruct-onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\pipelines\\pipelines_base.py:357\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, tokenizer, feature_extractor, use_fast, token, accelerator, revision, trust_remote_code, *model_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m     load_feature_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m model, model_id, tokenizer, feature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mMAPPING_LOADING_FUNC\u001b[49m\u001b[43m[\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargeted_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_feature_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSUPPORTED_TASKS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported_tasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m load_tokenizer:\n\u001b[0;32m    373\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m get_preprocessor(model_id)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\pipelines\\pipelines_base.py:253\u001b[0m, in \u001b[0;36mload_ort_pipeline\u001b[1;34m(model, targeted_task, load_tokenizer, tokenizer, feature_extractor, load_feature_extractor, SUPPORTED_TASKS, subfolder, token, revision, model_kwargs, config, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     onnx_files \u001b[38;5;241m=\u001b[39m find_files_matching_pattern(\n\u001b[0;32m    245\u001b[0m         model,\n\u001b[0;32m    246\u001b[0m         pattern,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    251\u001b[0m     )\n\u001b[0;32m    252\u001b[0m     export \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(onnx_files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 253\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mort_model_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, ORTModel):\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m load_tokenizer:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\onnxruntime\\modeling_ort.py:669\u001b[0m, in \u001b[0;36mORTModel.from_pretrained\u001b[1;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, provider, session_options, provider_options, use_io_binding, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;129m@add_start_docstrings\u001b[39m(FROM_PRETRAINED_START_DOCSTRING)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    637\u001b[0m ):\n\u001b[0;32m    638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m    provider (`str`, defaults to `\"CPUExecutionProvider\"`):\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m        ONNX Runtime provider to use for loading the model. See https://onnxruntime.ai/docs/execution-providers/ for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;124;03m        `ORTModel`: The loaded ORTModel model.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_io_binding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_io_binding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\modeling_base.py:373\u001b[0m, in \u001b[0;36mOptimizedModel.from_pretrained\u001b[1;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.json not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m local folder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 373\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[0;32m    383\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_load_config(\n\u001b[0;32m    384\u001b[0m         config,\n\u001b[0;32m    385\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    391\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\optimum\\modeling_base.py:231\u001b[0m, in \u001b[0;36mOptimizedModel._load_config\u001b[1;34m(cls, config_name_or_path, revision, cache_dir, use_auth_token, force_download, subfolder, trust_remote_code)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_config\u001b[39m(\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m     trust_remote_code: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    229\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PretrainedConfig:\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# if config not found in subfolder, search for it at the top level\u001b[39;00m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m subfolder \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:931\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    929\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    930\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n\u001b[1;32m--> 931\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_trust_remote_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_local_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_remote_code\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[0;32m    936\u001b[0m     class_ref \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\transformers\\dynamic_module_utils.py:627\u001b[0m, in \u001b[0;36mresolve_trust_remote_code\u001b[1;34m(trust_remote_code, model_name, has_local_code, has_remote_code)\u001b[0m\n\u001b[0;32m    624\u001b[0m         _raise_timeout_error(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_local_code \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n\u001b[1;32m--> 627\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    628\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires you to execute the configuration file in that\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    629\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m repo on your local machine. Make sure you have read the code there to avoid malicious use, then\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set the option `trust_remote_code=True` to remove this error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    631\u001b[0m     )\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trust_remote_code\n",
      "\u001b[1;31mValueError\u001b[0m: Loading microsoft/Phi-3-mini-4k-instruct-onnx requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error."
     ]
    }
   ],
   "source": [
    "from optimum.pipelines import pipeline\n",
    "pipe = pipeline(\"text-generation\", model=\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True, accelerator=\"ort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbebfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wengz\\anaconda3\\envs\\gen_ai_test\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wengz\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e14bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ai_test",
   "language": "python",
   "name": "gen_ai_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
