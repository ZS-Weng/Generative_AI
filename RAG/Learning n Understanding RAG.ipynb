{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d13502f",
   "metadata": {},
   "source": [
    "## Notebook on learning about RAG\n",
    "\n",
    "- Good resource: https://learnbybuilding.ai/tutorials/rag-from-scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ea8d3",
   "metadata": {},
   "source": [
    "### Benefits of RAG written in the tutorial\n",
    "\n",
    "- You can include facts in the prompt to help the LLM avoid hallucinations\n",
    "- You can (manually) refer to sources of truth when responding to a user query, helping to double check any potential issues.\n",
    "- You can leverage data that the LLM might not have been trained on.\n",
    "\n",
    "### The High Level Components of our RAG System\n",
    "- a collection of documents (formally called a corpus)\n",
    "- An input from the user\n",
    "- a similarity measure between the collection of documents and the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e02811",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce4c8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(query, document):\n",
    "    query = query.lower().split(\" \")\n",
    "    document = document.lower().split(\" \")\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619aa1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_response(query, corpus):\n",
    "    similarities = []\n",
    "    for doc in corpus:\n",
    "        similarity = jaccard_similarity(user_input, doc)\n",
    "        similarities.append(similarity)\n",
    "    return corpus_of_documents[similarities.index(max(similarities))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cedb14f",
   "metadata": {},
   "source": [
    "## Understanding in the lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654a224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How should I take a walk ?\"\n",
    "document = corpus_of_documents[0]\n",
    "query = query.lower().split(\" \")\n",
    "document = document.lower().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d86c699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'take', 'a', 'walk'} \n",
      " {'i', 'park', 'walk', 'in', 'enjoy', 'how', 'fresh', 'take', 'should', 'the', 'air.', 'leisurely', 'and', 'a', '?'}\n"
     ]
    }
   ],
   "source": [
    "intersection = set(query).intersection(set(document))\n",
    "union = set(query).union(set(document))\n",
    "print(intersection, \"\\n\", union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6419f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How should I take a walk ?\"\n",
    "corpus = corpus_of_documents\n",
    "similarities = []\n",
    "for doc in corpus:\n",
    "    similarity = jaccard_similarity(query, doc)\n",
    "    similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88710dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8efb8c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.index(max(similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5571b2",
   "metadata": {},
   "source": [
    "## Implemenation of an Open Source Semantic Search model\n",
    "\n",
    "- Chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2b8e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63cdff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # imports the pymupdf library\n",
    "doc = fitz.open(\"2022ltr.pdf\") # open a document\n",
    "pdf_texts =  [page.get_text() for page in doc] # iterate the document pages\n",
    "pdf_texts = [text for text in pdf_texts if len(text)>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80017f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BERKSHIRE HATHAWAY INC.\\nTo the Shareholders of Berkshire Hathaway Inc.:\\nCharlie Munger, my long-time partner, and I have the job of managing the savings of a\\ngreat number of individuals. We are grateful for their enduring trust, a relationship that often spans\\nmuch of their adult lifetime. It is those dedicated savers that are forefront in my mind as I write\\nthis letter.\\nA common belief is that people choose to save when young, expecting thereby to maintain\\ntheir living standards after retirement. Any assets that remain at death, this theory says, will usually\\nbe left to their families or, possibly, to friends and philanthropy.\\nOur experience has differed. We believe Berkshire’s individual holders largely to be of the\\nonce-a-saver, always-a-saver variety. Though these people live well, they eventually dispense\\nmost of their funds to philanthropic organizations. These, in turn, redistribute the funds by\\nexpenditures intended to improve the lives of a great many people who are unrelated to the original\\nbenefactor. Sometimes, the results have been spectacular.\\nThe disposition of money unmasks humans. Charlie and I watch with pleasure the vast flow\\nof Berkshire-generated funds to public needs and, alongside, the infrequency with which our\\nshareholders opt for look-at-me assets and dynasty-building.\\nWho wouldn’t enjoy working for shareholders like ours?\\nWhat We Do\\nCharlie and I allocate your savings at Berkshire between two related forms of ownership.\\nFirst, we invest in businesses that we control, usually buying 100% of each. Berkshire directs\\ncapital allocation at these subsidiaries and selects the CEOs who make day-by-day operating\\ndecisions. When large enterprises are being managed, both trust and rules are essential. Berkshire\\nemphasizes the former to an unusual – some would say extreme – degree. Disappointments are\\ninevitable. We are understanding about business mistakes; our tolerance for personal misconduct\\nis zero.\\nIn our second category of ownership, we buy publicly-traded stocks through which we\\npassively own pieces of businesses. Holding these investments, we have no say in management.\\n3\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5740bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9315ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the math: See’s rang up about 10 sales per minute during its prime operating time\n",
      "(racking up $400,309 of volume during the two days), with all the goods purchased at a single\n",
      "location selling products that haven’t been materially altered in 101 years. What worked for See’s\n",
      "in the days of Henry Ford’s model T works now.\n",
      "* * * * * * * * * * * *\n",
      "Charlie, I, and the entire Berkshire bunch look forward to seeing you in Omaha on\n",
      "May 5-6. We will have a good time and so will you.\n",
      "February 25, 2023\n",
      "Warren E. Buffett\n",
      "Chairman of the Board\n",
      "11\n",
      "\n",
      "Total chunks: 36\n"
     ]
    }
   ],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "print(character_split_texts[35])\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3407a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do the math : see ’ s rang up about 10 sales per minute during its prime operating time ( racking up $ 400, 309 of volume during the two days ), with all the goods purchased at a single location selling products that haven ’ t been materially altered in 101 years. what worked for see ’ s in the days of henry ford ’ s model t works now. * * * * * * * * * * * * charlie, i, and the entire berkshire bunch look forward to seeing you in omaha on may 5 - 6. we will have a good time and so will you. february 25, 2023 warren e. buffett chairman of the board 11\n",
      "\n",
      "Total chunks: 46\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(token_split_texts[45])\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e66068e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.json: 100%|███████████████████████████████████████████████████████████████████████████| 349/349 [00:00<?, ?B/s]\n",
      "C:\\Users\\wengz\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wengz\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "config_sentence_transformers.json: 100%|██████████████████████████████████████████████████████| 116/116 [00:00<?, ?B/s]\n",
      "README.md: 100%|██████████████████████████████████████████████████████████████████████████| 10.7k/10.7k [00:00<?, ?B/s]\n",
      "sentence_bert_config.json: 100%|████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "config.json: 100%|████████████████████████████████████████████████████████████████████████████| 612/612 [00:00<?, ?B/s]\n",
      "pytorch_model.bin: 100%|██████████████████████████████████████████████████████████| 90.9M/90.9M [00:00<00:00, 93.2MB/s]\n",
      "tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████| 350/350 [00:00<?, ?B/s]\n",
      "vocab.txt: 100%|████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 1.05MB/s]\n",
      "tokenizer.json: 100%|████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 638kB/s]\n",
      "special_tokens_map.json: 100%|████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 45.8kB/s]\n",
      "1_Pooling/config.json: 100%|██████████████████████████████████████████████████████████████████| 190/190 [00:00<?, ?B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.012467734515666962, -0.05428552255034447, 0.037649743258953094, -0.02378346025943756, 0.011054451577365398, 0.02136710099875927, -0.06601178646087646, -0.002584449015557766, 0.01125031616538763, -0.026465097442269325, 0.021672572940587997, 0.08212035149335861, -0.02570822462439537, -0.05478880926966667, -0.019596856087446213, -0.026295682415366173, 0.08333292603492737, -0.06668368726968765, -0.003572107758373022, -0.06448515504598618, -0.02125905081629753, -0.0254600141197443, -0.05526052787899971, 0.026272263377904892, -0.01911891996860504, 0.009858915582299232, -0.015476008877158165, -0.0454326868057251, -0.027211172506213188, -0.06809180229902267, -0.10900609940290451, -0.0048833186738193035, -0.041496992111206055, 0.01615954376757145, 0.013104509562253952, -0.04445979371666908, 0.06840939819812775, -0.060902856290340424, 0.04529665783047676, -0.05040785297751427, 0.07744777202606201, -0.04709912836551666, -0.04672233387827873, -0.017751457169651985, 0.07489844411611557, 0.016270417720079422, 0.04388357698917389, 0.11512205004692078, 0.04081427678465843, 0.01337850745767355, -0.09153995662927628, 0.017361653968691826, -0.044410426169633865, -0.08701522648334503, -0.05975135788321495, 0.10621161758899689, 0.00823866855353117, -0.027469288557767868, 0.006793755106627941, 0.0025355236139148474, 0.033523011952638626, -0.0918697789311409, 0.0324038602411747, 0.009494616650044918, 0.03698417544364929, 0.02920786663889885, -0.08006119728088379, -0.022133775055408478, -0.07310070097446442, 0.031024377793073654, 0.006625120062381029, -0.0067049176432192326, -0.0139502277597785, -0.008831603452563286, -0.03570624813437462, -0.0592883862555027, 0.07602732628583908, -0.022726934403181076, 0.04920072481036186, -0.025856900960206985, -0.035155389457941055, -0.037047307938337326, -0.055110737681388855, -0.04341666400432587, -0.0032733588013798, -0.04491177573800087, 0.024930011481046677, 0.04584571346640587, 0.07261548191308975, -0.057157691568136215, -0.012116988189518452, -0.02322476916015148, -0.052646465599536896, -0.018416590988636017, -0.13621439039707184, -0.015065073035657406, 0.0015929985092952847, 0.0968254804611206, -0.030156061053276062, 0.0330643393099308, 0.020262038335204124, 0.127543106675148, 0.022033916786313057, -0.08231010288000107, -0.1279505044221878, -0.012395595200359821, 0.00015406716556753963, 0.1187783032655716, 0.027363847941160202, 0.02710680104792118, -0.061389271169900894, 0.02898043394088745, 0.02255774661898613, -0.061217404901981354, -0.05271302908658981, -0.004338503815233707, -0.0388883613049984, -0.06158735975623131, 0.05732757970690727, -0.007183299865573645, 0.1193302720785141, 0.1122124195098877, 0.05645042285323143, 0.08006945252418518, -0.0769575908780098, 0.03382766991853714, 0.013946662656962872, 1.9643225082400533e-33, -0.04063413292169571, -0.010819386690855026, 0.040554195642471313, -0.01648377627134323, -0.008976412937045097, 0.04253576323390007, -0.030332855880260468, -0.07849302142858505, -0.009044576436281204, 0.023378299549221992, 0.012828214094042778, -0.04674139246344566, -0.035647809505462646, 0.002722271019592881, 0.005559652578085661, -0.08468582481145859, 0.04115716367959976, 0.029436152428388596, 0.026771636679768562, -0.09659630805253983, 0.0023510728497058153, -0.04695645719766617, -0.07301563024520874, -0.0028912147972732782, 0.023459114134311676, -0.004399844910949469, -0.004540279041975737, 0.02817082777619362, 0.0130142942070961, 0.04565799608826637, 0.08517032861709595, 0.12059515714645386, -0.09447059035301208, -0.017398308962583542, -0.06602457165718079, -0.017837395891547203, -0.007903927005827427, -0.05357541888952255, 0.10234574228525162, -0.09594576805830002, -0.07608769834041595, 0.06854008138179779, 0.03387945890426636, -0.027054550126194954, -0.05555512383580208, 0.017269916832447052, 0.10273362696170807, 0.09309326112270355, 0.01815938577055931, 0.0013228956377133727, -0.08230724930763245, -0.015453102067112923, 0.04333340376615524, 0.011398511938750744, -0.010177157819271088, -0.034997425973415375, 0.0076638078317046165, -0.09278253465890884, 0.011377960443496704, 0.01624978706240654, 0.08639577776193619, 0.08101734519004822, 0.011446270160377026, 0.024012867361307144, -0.17709992825984955, 0.09735089540481567, 0.04299301281571388, 0.00935098621994257, -0.01044517569243908, 0.0925411581993103, 0.10087248682975769, 0.0049667758867144585, 0.03146492317318916, -0.08096455782651901, 0.03499830514192581, -0.04934541508555412, 0.05192093923687935, 0.003076043911278248, 0.08170250803232193, 0.05989013612270355, 0.053060829639434814, -0.05741119384765625, 0.036876849830150604, 0.019664356485009193, 0.06395161896944046, 0.039275623857975006, 0.025246288627386093, -0.013260708190500736, 0.0029740945901721716, -0.013389445841312408, 0.004467286169528961, -0.004224961157888174, 0.04421495646238327, 0.057754985988140106, -0.02399374544620514, -3.749753143384186e-33, -0.039862003177404404, 0.017725564539432526, 0.030118023976683617, -0.013622567057609558, -0.052312254905700684, -0.09232281893491745, -0.04267428442835808, 0.06041155755519867, 0.001489965827204287, -0.013101343996822834, -0.052496131509542465, 0.050226934254169464, -0.02263774536550045, -0.03254348784685135, -0.04090793803334236, -0.01848706603050232, 0.13529770076274872, -0.06063840538263321, 0.062453776597976685, -0.07041114568710327, 0.025574900209903717, 0.00683961296454072, -0.06749928742647171, 0.016969040036201477, -0.03756901994347572, 0.05369553714990616, 0.023542247712612152, 0.007032283116132021, -0.030139824375510216, -0.10239946097135544, -0.09089936316013336, -0.05848846584558487, -0.03048205003142357, 0.0686674565076828, -0.014937475323677063, 0.0004830970137845725, 0.014606175012886524, -0.021516280248761177, 0.012521914206445217, -0.05047817900776863, 0.06332079321146011, -0.017677435651421547, -0.011792323552072048, 0.017487429082393646, 0.02478894405066967, 0.046104248613119125, 0.02594153955578804, 0.030529042705893517, 0.06112968176603317, 0.09002084285020828, -0.027855947613716125, 0.02887093834578991, 0.024166064336895943, 0.03191343694925308, -0.08654240518808365, 0.0649852529168129, 0.045300889760255814, 0.01905837096273899, -0.040079835802316666, -0.011395602487027645, -0.0004823681083507836, 0.05134503170847893, 0.004446709994226694, 0.04563996568322182, 0.01732843741774559, -0.060062944889068604, 0.014314540661871433, -0.02247176505625248, 0.0436621755361557, 0.00013079823111183941, -0.0023668273352086544, -0.025252601131796837, -0.06394464522600174, -0.07349810749292374, -0.02121778577566147, 0.08652467280626297, 0.030526915565133095, 0.027590760961174965, 0.0002873373741749674, 0.020030619576573372, -0.06737039238214493, -0.006077103782445192, 0.029869528487324715, -0.023509422317147255, 0.030618775635957718, 0.02264999784529209, 0.006062669679522514, -0.019230015575885773, -0.004782724194228649, 0.0922505334019661, -0.06152433902025223, -0.02732999436557293, -0.0034875308629125357, 0.019230026751756668, -0.03886675462126732, -4.9227747211944006e-08, 0.06261337548494339, 0.005570422857999802, 0.07000184804201126, -0.03292569890618324, 0.07600996643304825, -0.08808532357215881, 0.040107954293489456, 0.037450991570949554, -0.016938095912337303, 0.009976672008633614, 0.012307576835155487, -0.01260110642760992, -0.024086108431220055, 0.006967518012970686, 0.022596577182412148, -0.02955503575503826, -0.032187268137931824, -0.03658805787563324, -0.024897251278162003, -0.06197062134742737, 0.0024513020180165768, 0.035185012966394424, 0.13533304631710052, 0.0021127841901034117, -0.04549028351902962, 0.06390628963708878, 0.008539990521967411, 0.0445159375667572, 0.010151383467018604, 0.011128980666399002, -0.04176098108291626, -0.007519041653722525, -0.02037615329027176, -0.025944871827960014, 0.00809503998607397, -0.0718160942196846, -0.13540847599506378, 0.045145392417907715, -0.01638454757630825, 0.011370145715773106, -0.036067672073841095, -0.04218999296426773, 0.007682261057198048, 0.07460904121398926, 0.08479833602905273, -0.020251717418432236, -0.0632578507065773, -0.014723489992320538, 0.006335030309855938, -0.05858225002884865, -0.012562839314341545, 0.01961504854261875, -0.01589898020029068, -0.03447437286376953, 0.0017600433202460408, -0.003507043235003948, 0.04166217893362045, -0.059219345450401306, -0.004755656234920025, 0.030771588906645775, 0.05344247445464134, -0.13006842136383057, -0.10022895038127899, 0.055306147783994675]]\n"
     ]
    }
   ],
   "source": [
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "print(embedding_function([token_split_texts[45]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f8edf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./chromadb\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"Berkshire_Annual_Report\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d67f4106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=Berkshire_Annual_Report)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./chromadb\")\n",
    "chroma_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9434e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./chromadb\")\n",
    "chroma_collection = chroma_client.get_collection(\"Berkshire_Annual_Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a8858f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................. 15. 8 28. 7 2004......................................................................... 4. 3 10. 9 2005......................................................................... 0. 8 4. 9\n",
      "\n",
      "\n",
      "• patience can be learned. having a long attention span and the ability to concentrate on one thing for a long time is a huge advantage. • you can learn a lot from dead people. read of the deceased you admire and detest. • don ’ t bail away in a sinking boat if you can swim to one that is seaworthy. • a great company keeps working after you are not ; a mediocre company won ’ t do that. • warren and i don ’ t focus on the froth of the market. we seek out good long - term investments and stubbornly hold them for a long time. • ben graham said, “ day to day, the stock market is a voting machine ; in the long term it ’ s a weighing machine. ” if you keep making something more valuable, then some wise person is going to notice it and start buying. • there is no such thing as a 100 % sure thing when investing. thus, the use of leverage is dangerous. a string of wonderful numbers times zero will always equal zero. don ’ t count on getting rich twice.\n",
      "\n",
      "\n",
      "expenditures intended to improve the lives of a great many people who are unrelated to the original benefactor. sometimes, the results have been spectacular. the disposition of money unmasks humans. charlie and i watch with pleasure the vast flow of berkshire - generated funds to public needs and, alongside, the infrequency with which our shareholders opt for look - at - me assets and dynasty - building. who wouldn ’ t enjoy working for shareholders like ours? what we do charlie and i allocate your savings at berkshire between two related forms of ownership. first, we invest in businesses that we control, usually buying 100 % of each. berkshire directs capital allocation at these subsidiaries and selects the ceos who make day - by - day operating decisions. when large enterprises are being managed, both trust and rules are essential. berkshire emphasizes the former to an unusual – some would say extreme – degree. disappointments are\n",
      "\n",
      "\n",
      ".............................................................. 2. 7 26. 5 2010......................................................................... 21. 4 15. 1 2011......................................................................... ( 4. 7 ) 2. 1\n",
      "\n",
      "\n",
      ".............................................................. 35. 6 30. 5 1992......................................................................... 29. 8 7. 6 1993......................................................................... 38. 9 10. 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is your focus area?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c815c",
   "metadata": {},
   "source": [
    "## Using a local quantized LLM to fit into GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd3a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4278d45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6877f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
