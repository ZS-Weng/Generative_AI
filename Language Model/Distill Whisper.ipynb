{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016a6842-d69b-419b-9d8e-ad48fc895419",
   "metadata": {},
   "source": [
    "## Steps Involved in the setup\n",
    "\n",
    "1. Install librosa with conda install > There might be an error where the soundfile could not be found\n",
    "2. pip uninstall soundfile\n",
    "3. pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc18247-31aa-48b3-8a2b-9dfee4968fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from huggingface_hub import list_repo_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db7a4ce-6196-4c46-8a27-397fb5e70116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'model_id' with the ID of the model you want to download\n",
    "model_id = \"distil-whisper/distil-large-v3\"\n",
    "\n",
    "# List all files in the repository\n",
    "files = list_repo_files(repo_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17aecb5-2b89-4280-8739-8d0f6cfef792",
   "metadata": {},
   "source": [
    "# Download each file\n",
    "local_dir = \"C:/Users/wengz/Desktop/model_weights/distil-whisper/distil-large-v3\"\n",
    "for file in files:\n",
    "    file_path = hf_hub_download(repo_id=model_id, filename=file,local_dir=local_dir)\n",
    "    print(f\"Downloaded {file} to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f0b683-6519-45ec-a86d-0961a1a27c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soundfile']\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "print(torchaudio.list_audio_backends())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e286746a-d19b-488e-a4ee-3d6f9e1806c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Load and preprocess audio file\n",
    "audio_file = \"C:/Users/wengz/Desktop/2024-09-26 Planning Meeting.mp3\"\n",
    "audio_input, _ = librosa.load(audio_file, sr=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44bf28a-9f43-4dab-8eef-1f4e38b4bf5a",
   "metadata": {},
   "source": [
    "# Load audio using torchaudio\n",
    "audio_file = \"C:/Users/wengz/Desktop/2024-09-26 Planning Meeting.mp3\"\n",
    "waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "# Resample if necessary (Whisper requires 16kHz)\n",
    "resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "waveform = resampler(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954033b-c46e-4032-a9a4-34c27eb29669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "torch_dtype = torch.float16\n",
    "device = \"cpu\"\n",
    "\n",
    "model_id = \"C:/Users/wengz/Desktop/model_weights/distil-whisper/distil-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    return_timestamps=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "result = pipe(audio_input)\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8259524-871e-4ca0-bab0-9b665407cfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_gpu",
   "language": "python",
   "name": "ds_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
